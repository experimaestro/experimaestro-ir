# The configuration specific for SPLADE_doc
id: splade_doc
title: 'SPLADE_doc: SPLADEv2 model with document encoder only'
description: |
    SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval
    (Thibault Formal, Carlos Lassance, Benjamin Piwowarski, St√©phane Clinchant).
    2021. https://arxiv.org/abs/2109.10086

gpu: true
indexation:
    requirements: duration=2 days & cpu(mem=2G)
    training_requirements: duration=4 days & cuda(mem=24G)
learner:
    model: splade_doc
    validation_size: 500
    # validation for each (steps_per_epoch * validation interval) steps
    steps_per_epoch: 128
    validation_interval: 8
    # maybe it is too large for a gpu of 24G
    splade_batch_size: 48
    # About 50k steps for training
    max_epochs: 400
    num_warmup_steps: 6000
    early_stop: 0
    lr: 2.0e-5
    lambda_q: 0
    lambda_d: 1.0e-4
    lamdba_warmup_steps: 10000
    requirements: duration=6 days & cuda(mem=24G)
evaluation:
    requirements: duration=6 days & cuda(mem=24G)
base_retriever:
    topK: 1000
tas_balance_retriever:
    retTopK: 50
    indexspec: OPQ4_16,IVF65536_HNSW32,PQ4
    faiss_max_traindocs: 800_000
full_retriever:
    batch_size_full_retriever: 200
